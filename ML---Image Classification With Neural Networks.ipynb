{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is for Problem 9\n",
    "\n",
    "Image classification with neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for the training and test sets\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize to 64x64 pixels\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the dataset from the EuroSAT_RGB directory\n",
    "dataset = datasets.ImageFolder('EuroSAT_RGB', transform=transform)\n",
    "\n",
    "# Split the dataset into training (80%) and testing (20%) sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders for training and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, 11)  # 11 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleCNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|                                       | 0/675 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|█████| 675/675 [03:43<00:00,  3.03it/s, Loss=0.897, Acc=66.93%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.8969, Accuracy: 66.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|█████| 675/675 [02:45<00:00,  4.09it/s, Loss=0.493, Acc=82.34%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.4933, Accuracy: 82.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|█████| 675/675 [02:34<00:00,  4.36it/s, Loss=0.368, Acc=87.05%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.3684, Accuracy: 87.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|█████| 675/675 [02:35<00:00,  4.34it/s, Loss=0.268, Acc=90.41%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.2676, Accuracy: 90.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|█████| 675/675 [03:10<00:00,  3.54it/s, Loss=0.194, Acc=93.22%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.1938, Accuracy: 93.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|█████| 675/675 [02:36<00:00,  4.30it/s, Loss=0.147, Acc=94.92%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.1468, Accuracy: 94.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|█████| 675/675 [02:35<00:00,  4.34it/s, Loss=0.113, Acc=96.30%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.1135, Accuracy: 96.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|████| 675/675 [02:35<00:00,  4.33it/s, Loss=0.0896, Acc=97.14%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.0896, Accuracy: 97.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|████| 675/675 [02:54<00:00,  3.88it/s, Loss=0.0787, Acc=97.38%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.0787, Accuracy: 97.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|███| 675/675 [02:49<00:00,  3.99it/s, Loss=0.0777, Acc=97.51%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.0777, Accuracy: 97.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop with tqdm progress bar\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Use tqdm to create a progress bar for the current epoch\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{n_epochs}', ncols=80)\n",
    "    \n",
    "    for images, labels in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Update the progress bar description with the current loss and accuracy\n",
    "        progress_bar.set_postfix({'Loss': running_loss/len(train_loader), 'Acc': f'{100*correct/total:.2f}%'})\n",
    "\n",
    "    # Print epoch summary\n",
    "    train_accuracy = 100 * correct / total\n",
    "    print(f'Epoch {epoch+1}/{n_epochs}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/10: 100%|█████| 675/675 [03:43<00:00,  3.03it/s, Loss=0.897, Acc=66.93%]\n",
    "\n",
    "Epoch 1/10, Loss: 0.8969, Accuracy: 66.93%\n",
    "\n",
    "Epoch 2/10: 100%|█████| 675/675 [02:45<00:00,  4.09it/s, Loss=0.493, Acc=82.34%]\n",
    "\n",
    "Epoch 2/10, Loss: 0.4933, Accuracy: 82.34%\n",
    "\n",
    "Epoch 3/10: 100%|█████| 675/675 [02:34<00:00,  4.36it/s, Loss=0.368, Acc=87.05%]\n",
    "\n",
    "Epoch 3/10, Loss: 0.3684, Accuracy: 87.05%\n",
    "\n",
    "Epoch 4/10: 100%|█████| 675/675 [02:35<00:00,  4.34it/s, Loss=0.268, Acc=90.41%]\n",
    "\n",
    "Epoch 4/10, Loss: 0.2676, Accuracy: 90.41%\n",
    "\n",
    "Epoch 5/10: 100%|█████| 675/675 [03:10<00:00,  3.54it/s, Loss=0.194, Acc=93.22%]\n",
    "\n",
    "Epoch 5/10, Loss: 0.1938, Accuracy: 93.22%\n",
    "\n",
    "Epoch 6/10: 100%|█████| 675/675 [02:36<00:00,  4.30it/s, Loss=0.147, Acc=94.92%]\n",
    "\n",
    "Epoch 6/10, Loss: 0.1468, Accuracy: 94.92%\n",
    "\n",
    "Epoch 7/10: 100%|█████| 675/675 [02:35<00:00,  4.34it/s, Loss=0.113, Acc=96.30%]\n",
    "\n",
    "Epoch 7/10, Loss: 0.1135, Accuracy: 96.30%\n",
    "\n",
    "Epoch 8/10: 100%|████| 675/675 [02:35<00:00,  4.33it/s, Loss=0.0896, Acc=97.14%]\n",
    "\n",
    "Epoch 8/10, Loss: 0.0896, Accuracy: 97.14%\n",
    "\n",
    "Epoch 9/10: 100%|████| 675/675 [02:54<00:00,  3.88it/s, Loss=0.0787, Acc=97.38%]\n",
    "\n",
    "Epoch 9/10, Loss: 0.0787, Accuracy: 97.38%\n",
    "\n",
    "Epoch 10/10: 100%|███| 675/675 [02:49<00:00,  3.99it/s, Loss=0.0777, Acc=97.51%]\n",
    "\n",
    "Epoch 10/10, Loss: 0.0777, Accuracy: 97.51%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f'Test Set Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=dataset.classes, yticklabels=dataset.classes)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix / np.sum(conf_matrix, axis=1, keepdims=True), annot=True, fmt='.2%', cmap='Blues', xticklabels=dataset.classes, yticklabels=dataset.classes)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.title('Normalized Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Set Accuracy: 88.65%\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    "![alt text](images/conf_matrix1.png)\n",
    "\n",
    "![alt text](images/conf_matrix2.png)\n",
    "\n",
    "![alt text](images/conf_matrix3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 10 images in test set\n",
    "# predicted and actual values\n",
    "for i in range(10):\n",
    "    imshow(images[i], f'Predicted: {dataset.classes[preds[i]]}, Actual: {dataset.classes[labels[i]]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First 10 Predictions:\n",
    "\n",
    "![alt text](images/predicted_1.png)\n",
    "\n",
    "![alt text](images/predicted_2.png)\n",
    "\n",
    "![alt text](images/predicted_3.png)\n",
    "\n",
    "![alt text](images/predicted_4.png)\n",
    "\n",
    "![alt text](images/predicted_5.png)\n",
    "\n",
    "![alt text](images/predicted_6.png)\n",
    "\n",
    "![alt text](images/predicted_7.png)\n",
    "\n",
    "![alt text](images/predicted_8.png)\n",
    "\n",
    "![alt text](images/predicted_9.png)\n",
    "\n",
    "![alt text](images/predicted_10.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report = classification_report(all_labels, all_preds, target_names=dataset.classes)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report:\n",
    "\n",
    "![alt text](images/class_report.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Accuracy: 98.50%\n"
     ]
    }
   ],
   "source": [
    "topk = 3\n",
    "model.eval()\n",
    "correct_topk = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, topk_preds = torch.topk(outputs, topk, dim=1)\n",
    "        correct_topk += (topk_preds == labels.view(-1, 1)).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "topk_accuracy = 100 * correct_topk / total\n",
    "print(f'Top-{topk} Accuracy: {topk_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-3 Accuracy: 98.50%\n",
    "\n",
    "This means that 98.50% of the time, the correct class was within the top 3 predictions made by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model achieves a good accuracy score of 88.65%. The model is summed up through a confusion matrix (shown normalized and unnormalized), the printed results of the first 10 images in the testing set, a classification matrix, and a top-k accurracy calculation.\n",
    "\n",
    "The model is best at identifying images in the classes of SeaLake, Residential, and Forest. It struggles the most with HerbaciousVegetaion, PermanentCrop, and River."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
